{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3866417,"sourceType":"datasetVersion","datasetId":843852},{"sourceId":8073495,"sourceType":"datasetVersion","datasetId":4733451},{"sourceId":8355547,"sourceType":"datasetVersion","datasetId":4964924}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:38:47.136924Z\",\"iopub.execute_input\":\"2024-05-22T08:38:47.137261Z\",\"iopub.status.idle\":\"2024-05-22T08:39:20.258652Z\",\"shell.execute_reply.started\":\"2024-05-22T08:38:47.137236Z\",\"shell.execute_reply\":\"2024-05-22T08:39:20.257520Z\"}}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n!pip install matplotlib seaborn imgaug\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:20.260851Z\",\"iopub.execute_input\":\"2024-05-22T08:39:20.261417Z\",\"iopub.status.idle\":\"2024-05-22T08:39:26.137691Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:20.261379Z\",\"shell.execute_reply\":\"2024-05-22T08:39:26.136832Z\"}}\nimport cv2 as cv\nfrom skimage import io\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom scipy import ndimage\nfrom random import randrange\nimport imgaug.augmenters as iaa\nimport numpy as np\nfrom PIL import Image\nimport os\nimport glob\nfrom numpy import expand_dims\nimport tensorflow as tf\nimport keras\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras import layers\nfrom keras.layers import Dense, Activation\nimport torch\nfrom tensorflow.keras.metrics import F1Score\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.layers import LeakyReLU\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:26.138753Z\",\"iopub.execute_input\":\"2024-05-22T08:39:26.139359Z\",\"iopub.status.idle\":\"2024-05-22T08:39:26.145506Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:26.139330Z\",\"shell.execute_reply\":\"2024-05-22T08:39:26.144459Z\"}}\ndef rotate_image(image, angle):\n    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n    return result\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:26.148212Z\",\"iopub.execute_input\":\"2024-05-22T08:39:26.148565Z\",\"iopub.status.idle\":\"2024-05-22T08:39:26.153655Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:26.148537Z\",\"shell.execute_reply\":\"2024-05-22T08:39:26.152714Z\"}}\n#data_set=pd.read_csv(\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/train/_annotations.csv\")\n#data_counter=data_set.size\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:26.154754Z\",\"iopub.execute_input\":\"2024-05-22T08:39:26.155063Z\",\"iopub.status.idle\":\"2024-05-22T08:39:26.164377Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:26.155035Z\",\"shell.execute_reply\":\"2024-05-22T08:39:26.163527Z\"}}\ndef TOP_g_rotation(bbox):\n    imageNew = expand_dims(bbox, 0)\n    imageDataGen = ImageDataGenerator(rotation_range=30)\n    iterator = imageDataGen.flow(bbox, batch_size=1)\n    batch = iterator.next()\n    for i in range(9):\n\t# we are below define the subplot\n        plt.subplot(330 + 1 + i)\n\t# generating images of each batch\n        batch = iterator.next()\n\t# again we convert back to the unsigned integers value of the image for viewing\n        image = batch[0].astype('uint8')\n\t# we plot here raw pixel data\n        plt.imshow(image)\n    plt.show()\n    \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:26.165500Z\",\"iopub.execute_input\":\"2024-05-22T08:39:26.165823Z\",\"iopub.status.idle\":\"2024-05-22T08:39:26.172885Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:26.165780Z\",\"shell.execute_reply\":\"2024-05-22T08:39:26.171999Z\"}}\ndef visualize_class_column(df):\n  # Check if 'class' column exists\n  if 'class' not in df.columns:\n    raise ValueError(\"Dataframe does not contain a 'class' column\")\n  # Create the chart\n  plt.figure(figsize=(6, 6))\n  df['class'].value_counts().plot(kind='bar', color='royalblue')\n  plt.title('Distribution of Classes')\n  plt.xlabel('Class')\n  plt.ylabel('Count')\n  plt.xticks(rotation=0)  \n  # Display the chart\n  plt.tight_layout()\n  plt.show()\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:26.173975Z\",\"iopub.execute_input\":\"2024-05-22T08:39:26.174418Z\",\"iopub.status.idle\":\"2024-05-22T08:39:26.179477Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:26.174389Z\",\"shell.execute_reply\":\"2024-05-22T08:39:26.178483Z\"}}\n#visualize_class_column(data_set)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:26.180495Z\",\"iopub.execute_input\":\"2024-05-22T08:39:26.180829Z\",\"iopub.status.idle\":\"2024-05-22T08:39:26.186664Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:26.180796Z\",\"shell.execute_reply\":\"2024-05-22T08:39:26.185393Z\"}}\ndef rotateimage(image):\n    #print(np.shape(image))\n    r=randrange(-30, 30)\n    \n    r = ndimage.rotate(image,r)\n    #plt.imshow(rotated)\n    #plt.show()\n    #print(np.shape(r))\n    #print(\"mangawi_ana\")\n    return r\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:26.187965Z\",\"iopub.execute_input\":\"2024-05-22T08:39:26.188270Z\",\"iopub.status.idle\":\"2024-05-22T08:39:26.194826Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:26.188237Z\",\"shell.execute_reply\":\"2024-05-22T08:39:26.193754Z\"}}\ndef test_vizualize(x):\n    plt.imshow(x)\n    plt.show()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:26.198886Z\",\"iopub.execute_input\":\"2024-05-22T08:39:26.199161Z\",\"iopub.status.idle\":\"2024-05-22T08:39:26.205803Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:26.199138Z\",\"shell.execute_reply\":\"2024-05-22T08:39:26.204896Z\"}}\ndef image_edge(image):\n    bounding_box=cv.Canny(image,0,200 )\n    #plt.imshow(bounding_box)\n    #plt.show()\n    normalized=bounding_box/255\n    grayscale_images_reshaped = np.expand_dims(normalized, axis=-1)\n    return grayscale_images_reshaped\ndef image_gray(image):\n    bounding_box=cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n    #plt.imshow(bounding_box)\n    #plt.show()\n    normalized=bounding_box/255\n    grayscale_images_reshaped = np.expand_dims(normalized, axis=-1)\n    return grayscale_images_reshaped\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:26.206726Z\",\"iopub.execute_input\":\"2024-05-22T08:39:26.207009Z\",\"iopub.status.idle\":\"2024-05-22T08:39:26.216690Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:26.206985Z\",\"shell.execute_reply\":\"2024-05-22T08:39:26.215695Z\"}}\ndef al_incoding():\n    labels=[\"Car\",\"Motorcycle\",\"Pickup\",\"Truck\",\"Bus\"]\n        # One-hot encoding (using scikit-learn for illustration)\n    labels=np.array(labels)\n    encoder = OneHotEncoder(sparse=False)\n    encoded_labels = encoder.fit_transform(labels.reshape(-1, 1))\n    #print(\"al label\")\n    #print(encoded_labels)\n    #print(np.shape(encoded_labels))\n    #print(\"al label\")\n    mapping=[]\n    for i in range(len(labels)):\n        m=(labels[i],encoded_labels[i].reshape(5,1))\n        mapping.append(m)\n    #print(mapping)\n    return mapping\n    \ndef encodedd(labelx,mapped):\n    for (label,code) in mapped :\n        if(label==labelx):\n            #print((label,code))\n            return code\n            \n    \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:26.218028Z\",\"iopub.execute_input\":\"2024-05-22T08:39:26.218314Z\",\"iopub.status.idle\":\"2024-05-22T08:39:26.229708Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:26.218275Z\",\"shell.execute_reply\":\"2024-05-22T08:39:26.228884Z\"}}\n\ndef preprocessing(directory_main,csv):\n    data_set=pd.read_csv(csv)\n    visualize_class_column(data_set)\n    data_counter=data_set.size\n    i=0\n    #print(data_counter)\n    mapping=al_incoding()\n    data=[]\n\n    while(i < data_counter):\n        try:\n            image=str(data_set.iloc[i,0])\n            classs=data_set.iloc[i,3]\n            hot=encodedd(classs,mapping)\n            #print(classs)\n            box_coordinate_xmin=data_set.iloc[i,4]\n            box_coordinate_ymin=data_set.iloc[i,5]\n            box_coordinate_xmax=data_set.iloc[i,6]\n            box_coordinate_ymax=data_set.iloc[i,7]\n            image=directory_main+image\n            algowa=cv.imread(image)\n            bounding_box=algowa[box_coordinate_ymin:box_coordinate_ymax,box_coordinate_xmin:box_coordinate_xmax]\n            #print(algowa.shape)\n            bounding_box=cv.cvtColor(bounding_box, cv.COLOR_BGR2RGB)\n            bounding_box=cv.resize(bounding_box,(125,125),interpolation = cv.INTER_CUBIC )\n\n            #bounding_box=cv.resize(bounding_box,(125,125),interpolation = cv.INTER_CUBIC )\n            #print(bounding_box.shape)\n\n            #bounding_boxG=cv.resize(bounding_boxG,(125,125),interpolation = cv.INTER_CUBIC )\n            #r=rotateimage(bounding_box)\n            #print(np.shape(r))\n            #print(\"mangawi Fo2\")\n            image_edg=image_edge(bounding_box)\n            image_gry=image_gray(bounding_box)\n            #print(np.shape(image_gry))\n            #augmented=TOP_g_rotation(bounding_box)\n            #print(\"test1\")\n            #test_vizualize(augmented)\n            #print(\"test1\")\n           # image_edg=image_edge(r)\n            #image_gry=image_gray(r)\n            i_e=(image_edg,hot)\n            data.append(i_e)\n            i_g=(image_gry,hot)\n            #print(\"al incoding***********************************************************\")\n            #print(np.shape(hot))\n            #print(\"al incoding***********************************************************\")\n            data.append(i_g)\n\n\n\n\n            i=i+1\n        except:\n            i=i+1\n\n        #print(X)\n    print(len(data))\n    return data\n\n#x=preprocessing(\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/train/\",\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/train/_annotations.csv\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:26.230725Z\",\"iopub.execute_input\":\"2024-05-22T08:39:26.231048Z\",\"iopub.status.idle\":\"2024-05-22T08:39:26.238709Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:26.231019Z\",\"shell.execute_reply\":\"2024-05-22T08:39:26.237740Z\"}}\n#print(data)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:26.240068Z\",\"iopub.execute_input\":\"2024-05-22T08:39:26.240934Z\",\"iopub.status.idle\":\"2024-05-22T08:39:36.175155Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:26.240907Z\",\"shell.execute_reply\":\"2024-05-22T08:39:36.174161Z\"}}\n\n\ndata_path = \"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/train\"\n# os.mkdir('/rotation')\n# os.mkdir('/brightened')\n# os.mkdir('/darkened')\n\naugmentation = iaa.Sequential([\n    #randomly flip horizontaly\n    iaa.Fliplr(.5),\n    #randomly translate left & right, up & down to simulate cropped pictures\n    #rotation and scaling to simulate near and far cars\n    iaa.Affine(translate_percent={\"x\": (0, 0), \"y\":(0,0)},\n               rotate=(-20,20),\n               scale=(0.5,1.5)),\n    #randomly increase or decrease brightness\n    iaa.Multiply((0.2,1.7)),\n    #randomly bluring pictures for out of focus cars or really fast cars\n    iaa.Sometimes(0.2,\n                 iaa.GaussianBlur((0.0, 3.0)))\n    \n])\n\n\n\n# folderlen = len(data_path)\nfor img in glob.glob(data_path+\"/*.jpg\"):\n    image = cv.imread(img)\n    augmented_images = augmentation(image=image)\n    gray_images = cv.cvtColor(augmented_images, cv.COLOR_BGR2GRAY)\n    normalized_images = cv.normalize(\n    gray_images, None, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)\n    height, width = image.shape[:2]\n    plt.imshow(normalized_images)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:36.176516Z\",\"iopub.execute_input\":\"2024-05-22T08:39:36.176889Z\",\"iopub.status.idle\":\"2024-05-22T08:39:36.183375Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:36.176852Z\",\"shell.execute_reply\":\"2024-05-22T08:39:36.182390Z\"}}\ndef non_max_surpression(prediction,probability_thresh,iou_thresh,box=\"corners\"):\n    assert type(bbox)==list\n    bboxes = [box for box in bbboxes if box[1] > prob_threshold]\n    bboxes = sorted (bboxes, key=lambda x: x[1], reverse=True)\n    bboxes_after_nms = []\n    \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:36.184814Z\",\"iopub.execute_input\":\"2024-05-22T08:39:36.185143Z\",\"iopub.status.idle\":\"2024-05-22T08:39:36.192620Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:36.185118Z\",\"shell.execute_reply\":\"2024-05-22T08:39:36.191694Z\"}}\ndef separator(input_list):\n    matrix=[]\n    label=[]\n    for tupl in input_list:\n        matrix.append(np.array(tupl[0]))\n        label.append(np.array(tupl[1]))\n    return matrix,label\n        \n        \n    \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T09:11:18.643042Z\",\"iopub.execute_input\":\"2024-05-22T09:11:18.644023Z\",\"iopub.status.idle\":\"2024-05-22T09:11:18.660447Z\",\"shell.execute_reply.started\":\"2024-05-22T09:11:18.643986Z\",\"shell.execute_reply\":\"2024-05-22T09:11:18.659474Z\"}}\ndef model1():\n    model = keras.Sequential([\n        layers.Conv2D(32,(3,3),padding=\"same\",use_bias=\"false\",kernel_initializer=\"RandomNormal\"),\n        layers.Conv2D(16,(3,3),padding=\"same\",use_bias=\"false\",kernel_initializer=\"RandomNormal\"),\n        layers.Conv2D(4,(3,3),padding=\"same\",use_bias=\"false\",kernel_initializer=\"RandomNormal\"),\n        layers.Conv2D(16,(3,3),padding=\"same\",use_bias=\"false\",kernel_initializer=\"RandomNormal\"),\n        layers.Conv2D(4,(3,3),padding=\"same\",use_bias=\"false\",kernel_initializer=\"RandomNormal\"),\n        layers.Conv2D(16,(3,3),padding=\"same\",use_bias=\"false\",kernel_initializer=\"RandomNormal\"),\n        layers.Conv2D(4,(3,3),padding=\"same\",use_bias=\"false\",kernel_initializer=\"RandomNormal\"),\n        layers.Conv2D(16,(3,3),padding=\"same\",use_bias=\"false\",kernel_initializer=\"RandomNormal\"),\n        layers.Conv2D(4,(1,1),padding=\"same\",use_bias=\"true\",kernel_initializer=\"RandomNormal\"),\n        layers.MaxPool2D((7,7)),\n        layers.Flatten(),\n        layers.Dense(256, activation=LeakyReLU(alpha=0.01), name=\"layer1\"),\n        layers.Dropout(0.2),\n        layers.Dense(256, activation=LeakyReLU(alpha=0.01), name=\"layer2\"),\n        layers.Dropout(0.2),\n        layers.Dense(256,activation=LeakyReLU(alpha=0.01), name=\"layer3\"),\n        layers.Dropout(0.1),\n        layers.Dense(128, activation=\"relu\", name=\"layer4\"),\n        layers.Dropout(0.1),\n        layers.Dense(128,activation=LeakyReLU(alpha=0.01), name=\"layer5\"),\n        layers.Dense(128,activation=LeakyReLU(alpha=0.01), name=\"layer32\"),\n        layers.Dropout(0.1),\n        layers.Dense(128, activation=\"relu\"),\n        layers.Dropout(0.1),\n        layers.Dense(128,activation=LeakyReLU(alpha=0.01)),\n        layers.Dropout(0.1),\n        layers.Dense(64, activation=\"relu\"),\n        layers.Dropout(0.1),\n        layers.Dense(64,activation=LeakyReLU(alpha=0.01)),\n        layers.Dense(32,activation=LeakyReLU(alpha=0.01)),\n        layers.Dropout(0.1),\n        layers.Dense(32, activation=\"sigmoid\"),\n        layers.Dropout(0.1),\n        layers.Dense(16,activation=\"sigmoid\" ),\n        layers.Dropout(0.5),\n        layers.Dense(16,activation=\"relu\", name=\"layer6\"),\n        layers.Dense(8,activation=\"relu\", name=\"layer7\"),\n        layers.Dense(5,activation=\"sigmoid\",name=\"output\"),\n        layers.Reshape((5,1))\n    ]\n    )\n    model.compile(optimizer='adam',\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=['accuracy'])\n    \n    \n    return model\n    \n    \n    \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:36.211057Z\",\"iopub.execute_input\":\"2024-05-22T08:39:36.211458Z\",\"iopub.status.idle\":\"2024-05-22T08:39:36.225489Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:36.211425Z\",\"shell.execute_reply\":\"2024-05-22T08:39:36.224067Z\"}}\ntrain_data=preprocessing(\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/train/\",\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/train/_annotations.csv\")\nprint(\"pre_test_donr\")\nvalidation_data=preprocessing(\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/valid\",\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/valid/_annotations.csv\")\nprint(\"pre_val_donr\")\ntest_data=preprocessing(\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/test/\",\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/test/_annotations.csv\")\nprint(\"test pre done\")\nprint(\"train\")\ntrain_data=train_data+validation_data\n\nX_train,y_train=separator(train_data)\n\n\nX_test,y_test=separator(test_data)\n\n\nnum_folds = 5  \nshuffle_data = True  \n\n# Configure KFold\nkfold = KFold(n_splits=num_folds, shuffle=shuffle_data)\n\n\n# Cross-validation loop\nfold_no = 1\nscores = [] \nx_fold_train=[]\nx_fold_val=[]\ny_fold_train[]\n\nfor train_index, val_index in kfold.split(X_train):  # Here, we use X_train for splitting\n\n  # Select training and validation data from the main training set (X_train)\n  print(type(train_index))\n  print(train_index)\n  print(\"train_index\")\n    for i in train_index:\n        x_fold_train.append(X_train[i])\n    for i in val_index:\n        x_fold_val.append(X_train[i])\n        \n  #X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n  #y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n\n  # Create a new model instance for each fold (optional)\n  model = create_model()\n\n  # Train the model on the training data for this fold\n  model.fit(X_fold_train, y_fold_train, epochs=128, batch_size=32)\n  test_loss, test_acc = model.evaluate(X_test, y_test)\n  scores.append(test_acc)\n  model_weights = model.get_weights()\n  with open(f'fold_{fold_no}_weights.h5', 'wb') as f:\n    pickle.dump(model_weights, f)\n  model.save_weights(model_weights_path)\n  print(f'Fold {fold_no} - Test Accuracy: {test_acc:.4f}')\n  fold_no += 1\nprint('Average Test Accuracy:', np.mean(scores))\noutput(scores)\n\n\n    \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T09:11:27.651558Z\",\"iopub.execute_input\":\"2024-05-22T09:11:27.651957Z\",\"iopub.status.idle\":\"2024-05-22T09:24:14.692078Z\",\"shell.execute_reply.started\":\"2024-05-22T09:11:27.651925Z\",\"shell.execute_reply\":\"2024-05-22T09:24:14.691087Z\"}}\ntrain_data=preprocessing(\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/train/\",\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/train/_annotations.csv\")\nprint(\"pre_test_donr\")\nvalidation_data=preprocessing(\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/valid\",\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/valid/_annotations.csv\")\nprint(\"pre_val_donr\")\ntest_data=preprocessing(\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/test/\",\"/kaggle/input/vehicle-detection-image-dataset/Apply_Grayscale/Apply_Grayscale/Vehicles_Detection.v9i.tensorflow/test/_annotations.csv\")\nprint(\"test pre done\")\nprint(\"train\")\ntrain_data=train_data+validation_data\n\nX_train,y_train=separator(train_data)\n#print(type(X_train))\n\n\nmodel = model1()\nprint(model.summary())\n\nX_test,y_test=separator(test_data)\nmodel.fit(np.array(X_train), np.array(y_train), epochs=128, batch_size=32)\ntest_loss, test_acc = model.evaluate(np.array(X_test), np.array(y_test))\nprint(model.summary())\nprint('loss and acuracy:', test_loss,test_acc)\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-22T08:39:36.228037Z\",\"iopub.status.idle\":\"2024-05-22T08:39:36.228483Z\",\"shell.execute_reply.started\":\"2024-05-22T08:39:36.228257Z\",\"shell.execute_reply\":\"2024-05-22T08:39:36.228272Z\"}}\ndef output(scores):\n    plt.scatter(range(len(scores)), data_list)  # x-axis: data point index, y-axis: data value\n\n# Customize plot (optional)\n    plt.xlabel('iteration')\n    plt.ylabel('accuracy')\n    plt.grid(True)  # Add grid lines for better readability\n\n    # Display the plot\n    plt.show()","metadata":{"_uuid":"f469b7a6-75f3-4164-a30e-a75a16745c27","_cell_guid":"4be6ff11-d2d7-47e4-96ca-1e8117bfe1d7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}